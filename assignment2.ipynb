{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce245eaa",
   "metadata": {},
   "source": [
    "Required installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f80c42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets scikit-learn accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e2945",
   "metadata": {},
   "source": [
    "Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c319d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shiva\\anaconda3\\envs\\shiva\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\shiva\\anaconda3\\envs\\shiva\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0af4fb",
   "metadata": {},
   "source": [
    "Loading dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cea50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395fed9",
   "metadata": {},
   "source": [
    "Label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48de4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "label_list = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(label_list)\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "print(\"Labels:\", id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c39031",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e86730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,  # we'll pad dynamically with DataCollator\n",
    "        max_length=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1cf96f",
   "metadata": {},
   "source": [
    "Baseline fine-tuning (FP32/FP16):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba24f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 10145.80 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_8212\\3735649500.py:60: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Remove unused columns so Trainer only sees what it needs\n",
    "encoded_dataset = encoded_dataset.remove_columns([\"text\"])\n",
    "encoded_dataset.set_format(type=\"torch\")\n",
    "\n",
    "# ============================================================\n",
    "#  Load model (baseline FP32 / optional FP16 during training)\n",
    "# ============================================================\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "#  Data collator (dynamic padding)\n",
    "# ============================================================\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# ============================================================\n",
    "#  Metrics: accuracy + macro F1\n",
    "# ============================================================\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(logits, (tuple, list)):\n",
    "        logits = logits[0]\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"macro_f1\": macro_f1}\n",
    "\n",
    "# ============================================================\n",
    "#  Training arguments\n",
    "# ============================================================\n",
    "output_dir = \"bert_emotion_baseline\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    eval_strategy=\"steps\",  \n",
    "    save_strategy=\"steps\",  \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\", \n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "#  Trainer\n",
    "# ============================================================\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ddda9",
   "metadata": {},
   "source": [
    "#  Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5170206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 08:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.158021</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.907925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15802130103111267, 'eval_accuracy': 0.936, 'eval_macro_f1': 0.9079247244953336, 'eval_runtime': 4.4958, 'eval_samples_per_second': 444.863, 'eval_steps_per_second': 7.118, 'epoch': 3.0}\n",
      "\n",
      "Test metrics:\n",
      "{'eval_loss': 0.17462970316410065, 'eval_accuracy': 0.928, 'eval_macro_f1': 0.888150485686184, 'eval_runtime': 4.3657, 'eval_samples_per_second': 458.117, 'eval_steps_per_second': 7.33, 'epoch': 3.0}\n",
      "Model saved to: saved_bert_emotion_baseline\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# ============================================================\n",
    "#  Evaluate on validation and test\n",
    "# ============================================================\n",
    "print(\"Validation metrics:\")\n",
    "val_metrics = trainer.evaluate(encoded_dataset[\"validation\"])\n",
    "print(val_metrics)\n",
    "\n",
    "print(\"\\nTest metrics:\")\n",
    "test_metrics = trainer.evaluate(encoded_dataset[\"test\"])\n",
    "print(test_metrics)\n",
    "\n",
    "# ============================================================\n",
    "#  Save model & tokenizer (for GitHub upload)\n",
    "#    -> After this, you can zip the folder and commit to a public GitHub repo\n",
    "# ============================================================\n",
    "save_path = \"saved_bert_emotion_baseline\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "trainer.save_model(save_path)            # saves model + config\n",
    "tokenizer.save_pretrained(save_path)     # saves tokenizer files\n",
    "\n",
    "print(f\"Model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9377d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_save_path = save_path\n",
    "baseline_model_path = baseline_save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ab79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Bert_finetuning_on_dair-ai-emotion'...\n",
      "remote: Enumerating objects: 14, done.\u001b[K\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 14 (delta 1), reused 14 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (14/14), 315.65 KiB | 2.50 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c643c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model_path = \"Bert_finetuning_on_dair-ai-emotion/saved_bert_emotion_baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e195394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I am really happy with my results!\n",
      "Predicted emotion: joy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_8212\\1835544063.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  loaded_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics (reloaded model):\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17462970316410065, 'eval_model_preparation_time': 0.0071, 'eval_accuracy': 0.928, 'eval_macro_f1': 0.888150485686184, 'eval_runtime': 4.6525, 'eval_samples_per_second': 429.877, 'eval_steps_per_second': 6.878}\n",
      "\n",
      "Classification report (per-class metrics):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.95      0.98      0.96       581\n",
      "         joy       0.95      0.95      0.95       695\n",
      "        love       0.84      0.81      0.82       159\n",
      "       anger       0.96      0.88      0.92       275\n",
      "        fear       0.88      0.94      0.91       224\n",
      "    surprise       0.78      0.76      0.77        66\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.89      0.88      0.89      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    baseline_model_path,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(baseline_model_path)\n",
    "\n",
    "# ---------- Single-sentence inference demo ----------\n",
    "def predict_emotion(text):\n",
    "    inputs = loaded_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        pred_id = torch.argmax(logits, dim=-1).item()\n",
    "    return id2label[pred_id]\n",
    "\n",
    "example_text = \"I am really happy with my results!\"\n",
    "print(\"Text:\", example_text)\n",
    "print(\"Predicted emotion:\", predict_emotion(example_text))\n",
    "\n",
    "# ---------- Full test evaluation using loaded model ----------\n",
    "loaded_trainer = Trainer(\n",
    "    model=loaded_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=loaded_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nTest metrics (reloaded model):\")\n",
    "reloaded_test_metrics = loaded_trainer.evaluate()\n",
    "print(reloaded_test_metrics)\n",
    "\n",
    "# Optional: detailed per-class report (for your later assignment parts)\n",
    "preds_output = loaded_trainer.predict(encoded_dataset[\"test\"])\n",
    "logits = preds_output.predictions\n",
    "if isinstance(logits, (tuple, list)):\n",
    "    logits = logits[0]\n",
    "y_pred = np.argmax(logits, axis=-1)\n",
    "y_true = preds_output.label_ids\n",
    "\n",
    "print(\"\\nClassification report (per-class metrics):\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b855b",
   "metadata": {},
   "source": [
    "Post-Training Quantization (PTQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db912e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = baseline_save_path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "baseline_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    use_safetensors=True\n",
    ").to(\"cpu\")  # quantization is CPU-only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018924fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shiva\\anaconda3\\envs\\shiva\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e61f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16000/16000 [00:03<00:00, 5058.12 examples/s] \n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 11034.72 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 10908.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Accuracy: 0.922\n",
      "Quantized Model Macro F1: 0.8714083890030077\n",
      "\n",
      "Per-class metrics:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.94      0.97      0.96       581\n",
      "         joy       0.90      0.98      0.94       695\n",
      "        love       0.96      0.67      0.79       159\n",
      "       anger       0.96      0.88      0.92       275\n",
      "        fear       0.88      0.92      0.90       224\n",
      "    surprise       0.89      0.61      0.72        66\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.92      0.84      0.87      2000\n",
      "weighted avg       0.92      0.92      0.92      2000\n",
      "\n",
      "Baseline Model Size: 418.59 MB\n",
      "PTQ Model Size:      173.09 MB\n",
      "Baseline Latency: 73.65 ms\n",
      "Quantized Latency: 35.50 ms\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.quantization\n",
    "\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    baseline_model,\n",
    "    {torch.nn.Linear},     # Quantize linear layers\n",
    "    dtype=torch.qint8      # 8-bit weights\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "label_list = dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "def encode_batch(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "encoded = dataset.map(encode_batch, batched=True)\n",
    "encoded.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(encoded[\"test\"], batch_size=32)\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"]\n",
    "            )\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(batch[\"label\"].numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return acc, macro_f1, all_labels, all_preds\n",
    "\n",
    "acc, macro_f1, y_true, y_pred = evaluate(quantized_model)\n",
    "\n",
    "print(\"Quantized Model Accuracy:\", acc)\n",
    "print(\"Quantized Model Macro F1:\", macro_f1)\n",
    "print(\"\\nPer-class metrics:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_list))\n",
    "import os\n",
    "\n",
    "def get_size(path):\n",
    "    size = sum(os.path.getsize(os.path.join(path, f)) \n",
    "               for f in os.listdir(path))\n",
    "    return size / (1024 * 1024)  # MB\n",
    "\n",
    "baseline_size = get_size(model_path)\n",
    "torch.save(quantized_model.state_dict(), \"ptq_model.pth\")\n",
    "ptq_size = os.path.getsize(\"ptq_model.pth\") / (1024 * 1024)\n",
    "\n",
    "print(f\"Baseline Model Size: {baseline_size:.2f} MB\")\n",
    "print(f\"PTQ Model Size:      {ptq_size:.2f} MB\")\n",
    "import time\n",
    "\n",
    "def measure_latency(model, text=\"I feel great today!\"):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        _ = model(**inputs)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(50):\n",
    "        _ = model(**inputs)\n",
    "    end = time.time()\n",
    "\n",
    "    return (end - start) / 50\n",
    "\n",
    "baseline_latency = measure_latency(baseline_model)\n",
    "quantized_latency = measure_latency(quantized_model)\n",
    "\n",
    "print(f\"Baseline Latency: {baseline_latency*1000:.2f} ms\")\n",
    "print(f\"Quantized Latency: {quantized_latency*1000:.2f} ms\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=label_list, yticklabels=label_list)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (PTQ Model)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acd63a",
   "metadata": {},
   "source": [
    "Quantization-Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1913f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16000/16000 [00:01<00:00, 8645.07 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 8850.42 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 8774.68 examples/s]\n",
      "c:\\Users\\shiva\\anaconda3\\envs\\shiva\\Lib\\site-packages\\torch\\ao\\quantization\\quantize.py:392: UserWarning: None of the submodule got qconfig applied. Make sure you passed correct configuration through `qconfig_dict` or by assigning the `.qconfig` attribute directly on submodules\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 103.2378\n",
      "Epoch 2/2, Loss: 92.2957\n",
      "QAT training complete. Model saved at: qat_model_int8\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- PART 1: QAT TRAINING -----------------------\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "model_path = baseline_save_path   # your GitHub baseline path\n",
    "\n",
    "# Load tokenizer + dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "label_list = dataset[\"train\"].features[\"label\"].names\n",
    "num_labels = len(label_list)\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "encoded = dataset.map(preprocess, batched=True)\n",
    "encoded.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(encoded[\"train\"], batch_size=16, shuffle=True)\n",
    "\n",
    "# Load baseline FP32 model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "\n",
    "# ---------------- FREEZE LAYERS ----------------\n",
    "FREEZE_UP_TO = 8\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"bert.encoder.layer.\"):\n",
    "        layer_id = name.split(\".\")[3]\n",
    "        if layer_id.isdigit() and int(layer_id) < FREEZE_UP_TO:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# ---------------- PREPARE FOR QAT ----------------\n",
    "model.train()\n",
    "qat_model = torch.quantization.prepare_qat(model, inplace=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, qat_model.parameters()),\n",
    "    lr=1e-5\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---------------- TRAIN ----------------\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    qat_model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = qat_model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"]\n",
    "        )\n",
    "        loss = loss_fn(outputs.logits, batch[\"label\"])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# ---------------- CONVERT TO INT8 + SAVE ----------------\n",
    "qat_model.eval()\n",
    "quantized_int8_model = torch.quantization.convert(qat_model.to(\"cpu\"), inplace=False)\n",
    "\n",
    "# Save QAT model weights\n",
    "save_dir = \"qat_model_int8\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "torch.save(quantized_int8_model.state_dict(), f\"{save_dir}/model_int8.pth\")\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(\"QAT training complete. Model saved at:\", save_dir)\n",
    "# ----------------------- END OF PART 1 -----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a429d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2373892569.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    eval_model_path = \"C:\\Users\\shiva\\OneDrive\\Desktop\\nlp_assignment\\qat_model_int8\"      # folder created in part 1\u001b[0m\n\u001b[1;37m                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- PART 2: QAT EVALUATION -----------------------\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "# Load tokenizer + dataset again\n",
    "eval_model_path = \"qat_model_int8\"      # folder created in part 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(eval_model_path)\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "label_list = dataset[\"train\"].features[\"label\"].names\n",
    "\n",
    "def preprocess(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "encoded = dataset.map(preprocess, batched=True)\n",
    "encoded.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(encoded[\"test\"], batch_size=32)\n",
    "\n",
    "# Rebuild model in FP32 shape but load INT8 weights\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    baseline_save_path,  # restore model architecture\n",
    "    num_labels=len(label_list)\n",
    ")\n",
    "\n",
    "state = torch.load(f\"{eval_model_path}/model_int8.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# ---------------- EVALUATION ----------------\n",
    "def evaluate(model):\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            out = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"]\n",
    "            )\n",
    "            p = torch.argmax(out.logits, dim=1)\n",
    "            preds.extend(p.numpy())\n",
    "            trues.extend(batch[\"label\"].numpy())\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    macro_f1 = f1_score(trues, preds, average=\"macro\")\n",
    "    return acc, macro_f1, trues, preds\n",
    "\n",
    "acc, macro_f1, y_true, y_pred = evaluate(model)\n",
    "\n",
    "print(\"QAT Accuracy:\", acc)\n",
    "print(\"QAT Macro F1:\", macro_f1)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_list))\n",
    "\n",
    "# ---------------- LATENCY ----------------\n",
    "def measure_latency(model):\n",
    "    text = \"I feel amazing today!\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(5):\n",
    "        _ = model(**inputs)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(50):\n",
    "        _ = model(**inputs)\n",
    "    end = time.time()\n",
    "    return (end - start) / 50\n",
    "\n",
    "lat = measure_latency(model)\n",
    "print(f\"QAT Latency: {lat * 1000:.2f} ms\")\n",
    "\n",
    "# ---------------- CONFUSION MATRIX ----------------\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=label_list, yticklabels=label_list)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"QAT Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ----------------------- END OF PART 2 -----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc9f89d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets accelerate bitsandbytes peft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679172c6",
   "metadata": {},
   "source": [
    "Quantized Low Rank Adaptation (QLoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbdaafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d18fb891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\"],\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3398019/2172610896.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/data4/babu/Multilingual_factchecking/venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.071895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.071895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.071895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data4/babu/Multilingual_factchecking/venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/data4/babu/Multilingual_factchecking/venv/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.03048046875, metrics={'train_runtime': 358.4215, 'train_samples_per_second': 133.921, 'train_steps_per_second': 4.185, 'total_flos': 3206991495168000.0, 'train_loss': 0.03048046875, 'epoch': 3.0})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"qlora_bert_emotion\",\n",
    "#     learning_rate=2e-4,\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=32,\n",
    "#     logging_steps=50,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     bf16=True\n",
    "# )\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     import numpy as np\n",
    "#     from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "#     logits, labels = eval_pred\n",
    "#     preds = logits.argmax(axis=1)\n",
    "#     return {\n",
    "#         \"accuracy\": accuracy_score(labels, preds),\n",
    "#         \"macro_f1\": f1_score(labels, preds, average=\"macro\")\n",
    "#     }\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     train_dataset=encoded[\"train\"],\n",
    "#     eval_dataset=encoded[\"validation\"],\n",
    "#     args=training_args,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )\n",
    "\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6564f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qlora_lora_only/tokenizer_config.json',\n",
       " 'qlora_lora_only/special_tokens_map.json',\n",
       " 'qlora_lora_only/vocab.txt',\n",
       " 'qlora_lora_only/added_tokens.json',\n",
       " 'qlora_lora_only/tokenizer.json')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"qlora_lora_only\")\n",
    "tokenizer.save_pretrained(\"qlora_lora_only\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae6f53",
   "metadata": {},
   "source": [
    "Evalution of qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7204ff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2905\n",
      "Macro F1: 0.07503551594989022\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.29      1.00      0.45       581\n",
      "         joy       0.00      0.00      0.00       695\n",
      "        love       0.00      0.00      0.00       159\n",
      "       anger       0.00      0.00      0.00       275\n",
      "        fear       0.00      0.00      0.00       224\n",
      "    surprise       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.29      2000\n",
      "   macro avg       0.05      0.17      0.08      2000\n",
      "weighted avg       0.08      0.29      0.13      2000\n",
      "\n",
      "QLoRA adapter size (MB): 6.044393539428711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data4/babu/Multilingual_factchecking/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data4/babu/Multilingual_factchecking/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/data4/babu/Multilingual_factchecking/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference latency (ms): 31.00588321685791\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "eval_path = \"Bert_finetuning_on_dair-ai-emotion/qlora_lora_only\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(eval_path)\n",
    "from transformers import AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(label_list),\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "from peft import PeftModel\n",
    "\n",
    "qlora_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    eval_path,          # folder containing adapter_model.bin\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "qlora_model.eval()\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def evaluate(model):\n",
    "    preds, trues = [], []\n",
    "    model.eval()\n",
    "\n",
    "    for row in encoded[\"test\"]:\n",
    "        inputs = {\n",
    "            \"input_ids\": row[\"input_ids\"].unsqueeze(0).to(model.device),\n",
    "            \"attention_mask\": row[\"attention_mask\"].unsqueeze(0).to(model.device)\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "\n",
    "        preds.append(logits.argmax().item())\n",
    "        trues.append(row[\"label\"].item())\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(trues, preds))\n",
    "    print(\"Macro F1:\", f1_score(trues, preds, average=\"macro\"))\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(trues, preds, target_names=label_list))\n",
    "\n",
    "evaluate(qlora_model)\n",
    "import os, time\n",
    "\n",
    "# Model size (LoRA only)\n",
    "size_mb = sum(os.path.getsize(\"qlora_lora_only/\" + f)\n",
    "              for f in os.listdir(\"qlora_lora_only\")) / 1024**2\n",
    "print(\"QLoRA adapter size (MB):\", size_mb)\n",
    "\n",
    "# Latency\n",
    "def measure_latency(model):\n",
    "    inputs = tokenizer(\"I am very happy today!\", return_tensors=\"pt\").to(model.device)\n",
    "    for _ in range(5): model(**inputs)  # warmup\n",
    "    start = time.time()\n",
    "    for _ in range(20): model(**inputs)\n",
    "    return (time.time() - start) / 20\n",
    "\n",
    "print(\"Inference latency (ms):\", measure_latency(model) * 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shiva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
